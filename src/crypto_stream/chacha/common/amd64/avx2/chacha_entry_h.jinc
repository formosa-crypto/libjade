inline fn __chacha_xor_h_avx2(reg u64 output input len nonce key)
{
  reg u256[4] st k;
  reg u256 r16 r8;

  r16 = CHACHA_R16_AVX2;
  r8  = CHACHA_R8_AVX2;
  st = __init_h_avx2(nonce, key);

  while(len >= 128)
  {
    k = __copy_state_h_avx2(st);
    k = __rounds_h_avx2(k, r16, r8);
    k = __sum_states_h_avx2(k, st);
    k = __perm_h_avx2(k);
    output, input, len = __store_xor_h_avx2(output, input, len, k);
    st = __increment_counter0202_h_avx2(st);
  }

  if(len > 0)
  { k = __copy_state_h_avx2(st);
    k = __rounds_h_avx2(k, r16, r8);
    k = __sum_states_h_avx2(k, st);
    k = __perm_h_avx2(k);
    __store_xor_last_h_avx2(output, input, len, k);
  }
}


inline fn __chacha_xor_h_x2_avx2(reg u64 output input len nonce key)
{
  reg u256[4] st k1 k2;
  reg u256 r16 r8;

  r16 = CHACHA_R16_AVX2;
  r8  = CHACHA_R8_AVX2;
  st = __init_h_avx2(nonce, key);

/* Not needed in Benjamin's version 
  while(len >= 256)
  {
    k1, k2 = __copy_state_h_x2_avx2(st);
    k1, k2 = __rounds_h_x2_avx2(k1, k2, r16, r8);
    k1, k2 = __sum_states_h_x2_avx2(k1, k2, st);
    k1, k2 = __perm_h_x2_avx2(k1, k2);
    output, input, len = __store_xor_h_x2_avx2(output, input, len, k1, k2);
    st = __increment_counter0404_h_avx2(st);
  }
*/

  if(len > 128)
  { k1, k2 = __copy_state_h_x2_avx2(st);
    k1, k2 = __rounds_h_x2_avx2(k1, k2, r16, r8);
    k1, k2 = __sum_states_h_x2_avx2(k1, k2, st);
    k1, k2 = __perm_h_x2_avx2(k1, k2);
    output, input, len = __store_xor_h_avx2(output, input, len, k1);
    __store_xor_last_h_avx2(output, input, len, k2);
  }
  else
  { k1 = __copy_state_h_avx2(st);
    k1 = __rounds_h_avx2(k1, r16, r8);
    k1 = __sum_states_h_avx2(k1, st);
    k1 = __perm_h_avx2(k1);
    __store_xor_last_h_avx2(output, input, len, k1);
  }
}


//


inline fn __chacha_h_avx2(reg u64 output len nonce key)
{
  reg u256[4] st k;
  reg u256 r16 r8;

  r16 = CHACHA_R16_AVX2;
  r8  = CHACHA_R8_AVX2;
  st = __init_h_avx2(nonce, key);

  while(len >= 128)
  {
    k = __copy_state_h_avx2(st);
    k = __rounds_h_avx2(k, r16, r8);
    k = __sum_states_h_avx2(k, st);
    k = __perm_h_avx2(k);
    output, len = __store_h_avx2(output, len, k);
    st = __increment_counter0202_h_avx2(st);
  }

  if(len > 0)
  { k = __copy_state_h_avx2(st);
    k = __rounds_h_avx2(k, r16, r8);
    k = __sum_states_h_avx2(k, st);
    k = __perm_h_avx2(k);
    __store_last_h_avx2(output, len, k);
  }
}


inline fn __chacha_h_x2_avx2(reg u64 output len nonce key)
{
  reg u256[4] st k1 k2;
  reg u256 r16 r8;

  r16 = CHACHA_R16_AVX2;
  r8  = CHACHA_R8_AVX2;
  st = __init_h_avx2(nonce, key);

/* Not needed in Benjamin's version 
  while(len >= 256)
  {
    k1, k2 = __copy_state_h_x2_avx2(st);
    k1, k2 = __rounds_h_x2_avx2(k1, k2, r16, r8);
    k1, k2 = __sum_states_h_x2_avx2(k1, k2, st);
    k1, k2 = __perm_h_x2_avx2(k1, k2);
    output, len = __store_h_x2_avx2(output, len, k1, k2);
    st = __increment_counter0404_h_avx2(st);
  }
*/

  if(len > 128)
  { k1, k2 = __copy_state_h_x2_avx2(st);
    k1, k2 = __rounds_h_x2_avx2(k1, k2, r16, r8);
    k1, k2 = __sum_states_h_x2_avx2(k1, k2, st);
    k1, k2 = __perm_h_x2_avx2(k1, k2);
    output, len = __store_h_avx2(output, len, k1);
    __store_last_h_avx2(output, len, k2);
  }
  else
  { k1 = __copy_state_h_avx2(st);
    k1 = __rounds_h_avx2(k1, r16, r8);
    k1 = __sum_states_h_avx2(k1, st);
    k1 = __perm_h_avx2(k1);
    __store_last_h_avx2(output, len, k1);
  }
}

