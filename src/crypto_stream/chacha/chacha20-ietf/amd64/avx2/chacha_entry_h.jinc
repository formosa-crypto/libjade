#[returnaddress="stack"]
fn _chacha_xor_h_avx2_ic(reg u64 output input len nonce, reg u32 counter, reg u64 key)
{
  reg u256[4] st k;
  reg u256 r16 r8;

  r16 = CHACHA_R16_AVX2;
  r8  = CHACHA_R8_AVX2;
  st = __init_h_avx2(nonce, counter, key);

  while(len >= 128)
  {
    k = __copy_state_h_avx2(st);
    k = __rounds_h_avx2(k, r16, r8);
    k = __sum_states_h_avx2(k, st);
    k = __perm_h_avx2(k);
    output, input, len = __store_xor_h_avx2(output, input, len, k);
    st = __increment_counter0202_h_avx2(st);
  }

  if(len > 0)
  { k = __copy_state_h_avx2(st);
    k = __rounds_h_avx2(k, r16, r8);
    k = __sum_states_h_avx2(k, st);
    k = __perm_h_avx2(k);
    __store_xor_last_h_avx2(output, input, len, k);
  }
}

inline fn _chacha_xor_h_avx2_ic_(reg u64 _output _input _len _nonce, reg u32 _counter, reg u64 _key)
{
  reg u64 output input len nonce key;
  reg u32 counter;

  output = _output;
  input = _input;
  len = _len;
  nonce = _nonce;
  counter = _counter;
  key = _key;

  _chacha_xor_h_avx2_ic(output, input, len, nonce, counter, key);
}

inline fn __chacha_xor_h_avx2(reg u64 output input len nonce key)
{
  reg u32 counter;

  ?{}, counter = #set0_32();
  _chacha_xor_h_avx2_ic_(output, input, len, nonce, counter, key);
}

//

#[returnaddress="stack"]
fn _chacha_xor_h_x2_avx2_ic(reg u64 output input len nonce, reg u32 counter, reg u64 key)
{
  reg u256[4] st k1 k2;
  reg u256 r16 r8;

  r16 = CHACHA_R16_AVX2;
  r8  = CHACHA_R8_AVX2;
  st = __init_h_avx2(nonce, counter, key);

/* Not needed in benjamin's version
  while(len >= 256)
  {
    k1, k2 = __copy_state_h_x2_avx2(st);
    k1, k2 = __rounds_h_x2_avx2(k1, k2, r16, r8);
    k1, k2 = __sum_states_h_x2_avx2(k1, k2, st);
    k1, k2 = __perm_h_x2_avx2(k1, k2);
    output, input, len = __store_xor_h_x2_avx2(output, input, len, k1, k2);
    st = __increment_counter0404_h_avx2(st);
  }
*/

  if(len > 128)
  { k1, k2 = __copy_state_h_x2_avx2(st);
    k1, k2 = __rounds_h_x2_avx2(k1, k2, r16, r8);
    k1, k2 = __sum_states_h_x2_avx2(k1, k2, st);
    k1, k2 = __perm_h_x2_avx2(k1, k2);
    output, input, len = __store_xor_h_avx2(output, input, len, k1);
    __store_xor_last_h_avx2(output, input, len, k2);
  }
  else
  { k1 = __copy_state_h_avx2(st);
    k1 = __rounds_h_avx2(k1, r16, r8);
    k1 = __sum_states_h_avx2(k1, st);
    k1 = __perm_h_avx2(k1);
    __store_xor_last_h_avx2(output, input, len, k1);
  }
}

inline fn _chacha_xor_h_x2_avx2_ic_(reg u64 _output _input _len _nonce, reg u32 _counter, reg u64 _key)
{
  reg u64 output input len nonce key;
  reg u32 counter;

  output = _output;
  input = _input;
  len = _len;
  nonce = _nonce;
  counter = _counter;
  key = _key;

  _chacha_xor_h_x2_avx2_ic(output, input, len, nonce, counter, key);
}

inline fn __chacha_xor_h_x2_avx2(reg u64 output input len nonce key)
{
  reg u32 counter;

  ?{}, counter = #set0_32();
  _chacha_xor_h_x2_avx2_ic_(output, input, len, nonce, counter, key);
}

//

#[returnaddress="stack"]
fn _chacha_h_avx2_ic(reg u64 output len nonce, reg u32 counter, reg u64 key)
{
  reg u256[4] st k;
  reg u256 r16 r8;

  r16 = CHACHA_R16_AVX2;
  r8  = CHACHA_R8_AVX2;
  st = __init_h_avx2(nonce, counter, key);

  while(len >= 128)
  {
    k = __copy_state_h_avx2(st);
    k = __rounds_h_avx2(k, r16, r8);
    k = __sum_states_h_avx2(k, st);
    k = __perm_h_avx2(k);
    output, len = __store_h_avx2(output, len, k);
    st = __increment_counter0202_h_avx2(st);
  }

  if(len > 0)
  { k = __copy_state_h_avx2(st);
    k = __rounds_h_avx2(k, r16, r8);
    k = __sum_states_h_avx2(k, st);
    k = __perm_h_avx2(k);
    __store_last_h_avx2(output, len, k);
  }
}

inline fn _chacha_h_avx2_ic_(reg u64 _output _len _nonce, reg u32 _counter, reg u64 _key)
{
  reg u64 output len nonce key;
  reg u32 counter;

  output = _output;
  len = _len;
  nonce = _nonce;
  counter = _counter;
  key = _key;

  _chacha_h_avx2_ic(output, len, nonce, counter, key);
}

inline fn __chacha_h_avx2(reg u64 output len nonce key)
{
  reg u32 counter;

  ?{}, counter = #set0_32();
  _chacha_h_avx2_ic_(output, len, nonce, counter, key);
}

//

#[returnaddress="stack"]
fn _chacha_h_x2_avx2_ic(reg u64 output len nonce, reg u32 counter, reg u64 key)
{
  reg u256[4] st k1 k2;
  reg u256 r16 r8;

  r16 = CHACHA_R16_AVX2;
  r8  = CHACHA_R8_AVX2;
  st = __init_h_avx2(nonce, counter, key);

/* not needed in Benjamin's version
  while(len >= 256)
  {
    k1, k2 = __copy_state_h_x2_avx2(st);
    k1, k2 = __rounds_h_x2_avx2(k1, k2, r16, r8);
    k1, k2 = __sum_states_h_x2_avx2(k1, k2, st);
    k1, k2 = __perm_h_x2_avx2(k1, k2);
    output, len = __store_h_x2_avx2(output, len, k1, k2);
    st = __increment_counter0404_h_avx2(st);
  }
*/

  if(len > 128)
  { k1, k2 = __copy_state_h_x2_avx2(st);
    k1, k2 = __rounds_h_x2_avx2(k1, k2, r16, r8);
    k1, k2 = __sum_states_h_x2_avx2(k1, k2, st);
    k1, k2 = __perm_h_x2_avx2(k1, k2);
    output, len = __store_h_avx2(output, len, k1);
    __store_last_h_avx2(output, len, k2);
  }
  else
  { k1 = __copy_state_h_avx2(st);
    k1 = __rounds_h_avx2(k1, r16, r8);
    k1 = __sum_states_h_avx2(k1, st);
    k1 = __perm_h_avx2(k1);
    __store_last_h_avx2(output, len, k1);
  }
}

inline fn _chacha_h_x2_avx2_ic_(reg u64 _output _len _nonce, reg u32 _counter, reg u64 _key)
{
  reg u64 output len nonce key;
  reg u32 counter;

  output = _output;
  len = _len;
  nonce = _nonce;
  counter = _counter;
  key = _key;

  _chacha_h_x2_avx2_ic(output, len, nonce, counter, key);
}

inline fn __chacha_h_x2_avx2(reg u64 output len nonce key)
{
  reg u32 counter;

  ?{}, counter = #set0_32();
  _chacha_h_x2_avx2_ic_(output, len, nonce, counter, key);
}


