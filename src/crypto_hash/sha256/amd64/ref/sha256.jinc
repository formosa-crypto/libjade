
require "sha256_globals.jinc"

inline fn __initH_ref() -> stack u32[8]
{
  stack u32[8] H;

  H[0]  = 0x6a09e667;
  H[1]  = 0xbb67ae85;
  H[2]  = 0x3c6ef372;
  H[3]  = 0xa54ff53a;
  H[4]  = 0x510e527f;
  H[5]  = 0x9b05688c;
  H[6]  = 0x1f83d9ab;
  H[7]  = 0x5be0cd19;

  return H;
}

inline fn __load_H_ref(reg ptr u32[8] H) -> reg u32, reg u32, reg u32, reg u32,
                                            reg u32, reg u32, reg u32, reg u32,
                                            reg ptr u32[8]
{
  reg u32 a b c d e f g h;

  a = H[0];
  b = H[1];
  c = H[2];
  d = H[3];
  e = H[4];
  f = H[5];
  g = H[6];
  h = H[7];

  return a, b, c, d, e, f, g, h, H;
}

inline fn __store_H_ref(reg ptr u32[8] H, reg u32 a b c d e f g h) -> reg ptr u32[8]
{
  H[0] = a;
  H[1] = b;
  H[2] = c;
  H[3] = d;
  H[4] = e;
  H[5] = f;
  H[6] = g;
  H[7] = h;

  return H;
}

inline fn __store_ref(reg u64 out, stack u32[8] H)
{
  inline int i;
  reg u32 v;

  for i=0 to 8
  { v = H[i];
    v = #BSWAP_32(v);
    (u32)[out + i*4] = v;
  }
}

inline fn __SHR_ref(reg u32 x, inline int c) -> reg u32
{
  reg u32 r;
  r   = x;
  r >>= c;
  return r;
}

inline fn __ROTR_ref(reg u32 x, inline int c) -> reg u32
{
  reg u32 r;
  r = x;
  _, _, r = #ROR_32(r, c);
  return r;
}

//(x & y) ^ (!x & z)
inline fn __CH_ref(reg u32 x y z) -> reg u32
{
  reg u32 r s;

  r  =  x;
  r &=  y;
  s  =  x;
  s  = !s;
  s &=  z;
  r ^=  s;

  return r;
}

//(x & y) ^ (x & z) ^ (y & z)
inline fn __MAJ_ref(reg u32 x y z) -> reg u32
{
  reg u32 r s;

  r  = x;
  r &= y;
  s  = x;
  s &= z;
  r ^= s;
  s  = y;
  s &= z;
  r ^= s;

  return r;
}

// (x >>> 2) ^ (x >>> 13) ^ (x >>> 22)
inline fn __BSIG0_ref(reg u32 x) -> reg u32
{
  reg u32 r s;

  r  = __ROTR_ref(x, 2);
  s  = __ROTR_ref(x,13);
  r ^= s;
  s  = __ROTR_ref(x,22);
  r ^= s;

  return r;
}

// (x >>> 6) ^ (x >>> 11) ^ (x >>> 25)
inline fn __BSIG1_ref(reg u32 x) -> reg u32
{
  reg u32 r s;

  r  = __ROTR_ref(x, 6);
  s  = __ROTR_ref(x,11);
  r ^= s;
  s  = __ROTR_ref(x,25);
  r ^= s;

  return r;
}

// (x >>> 7) ^ (x >>> 18) ^ (x >> 3)
inline fn __SSIG0_ref(reg u32 x) -> reg u32
{
  reg u32 r s;

  r  = __ROTR_ref(x, 7);
  s  = __ROTR_ref(x,18);
  r ^= s;
  s  = __SHR_ref(x,3);
  r ^= s;

  return r;
}

// (x >>> 17) ^ (x >>> 19) ^ (x >> 10)
inline fn __SSIG1_ref(reg u32 x) -> reg u32
{
  reg u32 r s;

  r  = __ROTR_ref(x,17);
  s  = __ROTR_ref(x,19);
  r ^= s;
  s  = __SHR_ref(x,10);
  r ^= s;

  return r;
}

// Wt = SSIG1(W(t-2)) + W(t-7) + SSIG0(t-15) + W(t-16)
inline fn __Wt_ref(stack u32[64] W, inline int t) -> stack u32[64]
{
  reg u32 wt wt2 wt15;

  wt2  = W[t-2];
  wt   = __SSIG1_ref(wt2);
  wt  += W[t-7];
  wt15 = W[t-15];
  wt15 = __SSIG0_ref(wt15);
  wt  += wt15;
  wt  += W[t-16];

  W[t] = wt;

  return W;
}

fn _blocks_0_ref(reg ptr u32[8] _H, reg u64 in inlen) -> reg ptr u32[8], reg u64, reg u64
{
  inline int t;
  reg u32 T1 T2 a b c d e f g h r v;
  stack u32[64] W;
  reg ptr u32[64] Kp;
  stack ptr u32[8] Hp;
  reg ptr u32[8] H;
  reg u64 tr;
  stack u64 in_s;

  Kp = SHA256_K;
  Hp = _H;

  H = Hp;

  while(inlen >= 64)
  {
    for t=0 to 16
    { v = (u32)[in + t*4];
      v = #BSWAP_32(v);
      W[t] = v;
    }
    in_s = in;

    for t=16 to 64
    { W = __Wt_ref(W, t); }

    a, b, c, d, e, f, g, h, H = __load_H_ref(H);
    Hp = H;

    tr = 0;
    while(tr < 64)
    {
      //T1 = h + BSIG1(e) + CH(e,f,g) + Kt + Wt
      T1  = h;
      r   = __BSIG1_ref(e);
      T1 += r;
      r   = __CH_ref(e,f,g);
      T1 += r;
      T1 += Kp[(int)tr];
      T1 += W[(int)tr];

      //T2 = BSIG0(a) + MAJ(a,b,c)
      T2  = __BSIG0_ref(a);
      r   = __MAJ_ref(a,b,c);
      T2 += r;

      h  = g;
      g  = f;
      f  = e;
      e  = d;
      e += T1;
      d  = c;
      c  = b;
      b  = a;
      a  = T1;
      a += T2;

      tr+= 1;
    }

    H = Hp;
    a += H[0];
    b += H[1];
    c += H[2];
    d += H[3];
    e += H[4];
    f += H[5];
    g += H[6];
    h += H[7];

    H = __store_H_ref(H,a,b,c,d,e,f,g,h);
    //Hp = H;

    in = in_s;
    in += 64;
    inlen -= 64;
  }

  _H = H;
  return _H, in, inlen;
}

fn _blocks_1_ref(reg ptr u32[8] _H, reg ptr u32[32] sblocks, reg u64 nblocks) -> reg ptr u32[8], reg ptr u32[32]
{
  inline int t;
  reg u32 T1 T2 a b c d e f g h r v;
  stack u32[64] W;
  reg ptr u32[64] Kp;
  stack ptr u32[8] Hp;
  reg ptr u32[8] H;
  stack ptr u32[32] s_sblocks;
  reg u64 i oblocks tr;
  stack u64 s_i;

  Kp = SHA256_K;
  Hp = _H;
  i = 0;

  H = Hp;

  while(i < nblocks)
  {
    s_i = i;
    oblocks = i << 4;
    for t=0 to 16
    { v = sblocks[(int)oblocks + t];
      v = #BSWAP_32(v);
      W[t] = v;
    }
    s_sblocks = sblocks;

    for t=16 to 64
    { W = __Wt_ref(W, t); }

    a, b, c, d, e, f, g, h, H = __load_H_ref(H);
    Hp = H;

    tr = 0;
    while(tr < 64)
    {
      //T1 = h + BSIG1(e) + CH(e,f,g) + Kt + Wt
      T1  = h;
      r   = __BSIG1_ref(e);
      T1 += r;
      r   = __CH_ref(e,f,g);
      T1 += r;
      T1 += Kp[(int)tr];
      T1 += W[(int)tr];

      //T2 = BSIG0(a) + MAJ(a,b,c)
      T2  = __BSIG0_ref(a);
      r   = __MAJ_ref(a,b,c);
      T2 += r;

      h  = g;
      g  = f;
      f  = e;
      e  = d;
      e += T1;
      d  = c;
      c  = b;
      b  = a;
      a  = T1;
      a += T2;

      tr+= 1;
    }

    H = Hp;
    a += H[0];
    b += H[1];
    c += H[2];
    d += H[3];
    e += H[4];
    f += H[5];
    g += H[6];
    h += H[7];

    H = __store_H_ref(H,a,b,c,d,e,f,g,h);

    sblocks = s_sblocks;
    i = s_i;
    i += 1;
  }

  _H = H;
  return _H, sblocks;
}


inline fn __lastblocks_ref(reg u64 in inlen bits) -> stack u32[32], reg u64
{
  stack u32[32] sblocks;
  inline int k;
  reg u64 i j nblocks;
  reg u8 v;

  i = 0;

  // Zero-fill the sblocks array
  for k = 0 to 32 { sblocks[k] = i; }

  // copy in to sblocks
  while(i < inlen)
  { v = (u8)[in + i];
    sblocks[u8 (int)i] = v;
    i += 1;
  }

  // set first byte after input to 0x80 
  sblocks[u8 (int)i] = 0x80;

  // check if one or two blocks are needed
  if(inlen < 56) // 448 / 8 = 56
  { j = (64-8); nblocks = 1; i = 63; }
  else
  { j = (128-8); nblocks = 2; i = 127; }

  while(i >= j)
  { sblocks[u8 (int)i] = (8u) bits;
    bits >>= 8;
    i -= 1;
  }

  return sblocks, nblocks;
}

inline fn __sha256_ref(reg u64 out in inlen)
{
  reg u64 bits nblocks;
  stack u64 s_bits;
  regx u64 s_out;
  stack u32[8] H;
  reg ptr u32[8] Hp;
  stack u32[32] sblocks;
  reg ptr u32[32] sblocksp;

  s_out = out;

  bits = inlen;
  bits <<= 3;
  s_bits = bits;

  H = __initH_ref();
  Hp = H;
  Hp, in, inlen = _blocks_0_ref(Hp, in, inlen);

  bits = s_bits;
  sblocks, nblocks = __lastblocks_ref(in, inlen, bits);
  sblocksp = sblocks;
  Hp, _ = _blocks_1_ref(Hp, sblocksp, nblocks);

  out = s_out;
  H = Hp;
  __store_ref(out, H);
}
