// Note1: before this file is required, it is necessary to require the correspondent 'verify.jinc':
//        - for 'ref' implementations: crypto_kem/kyber/common/amd64/ref/verify.jinc
//        - for 'avx2' implementations: crypto_kem/kyber/common/amd64/avx2/verify.jinc
//
// Note2: due to the integration of hakyber implementations into libjade, this file is no longer
//        required by kyber768/amd64/ref/

#[returnaddress="stack"]
fn __crypto_kem_keypair_derand_jazz(reg u64 pkp, reg u64 skp, reg ptr u8[2*KYBER_SYMBYTES] coins)
{
  stack u8[32] h_pk;
  stack u64 s_skp s_pkp;
  stack ptr u8[2*KYBER_SYMBYTES] s_coins;
  reg u64 t64;
  inline int i;

  s_coins = coins;
  s_pkp = pkp;
  s_skp = skp;

  __indcpa_keypair_derand(pkp, skp, coins[0:32]);

  skp = s_skp;
  skp += KYBER_POLYVECBYTES;
  pkp = s_pkp;

  for i=0 to KYBER_INDCPA_PUBLICKEYBYTES/8
  {
    t64 = (u64)[pkp + 8*i];
    (u64)[skp] = t64;
    skp += 8;
  }

  s_skp = skp;
  pkp = s_pkp;
  t64 = KYBER_INDCPA_PUBLICKEYBYTES;
  h_pk = _sha3_256(h_pk, pkp, t64);
  skp = s_skp;
  coins = s_coins;

  __fromstack32u8(skp, h_pk);
    skp += 32;
  
  __fromstack32u8(skp, coins[32:32]);
}

#[returnaddress="stack"]
fn __crypto_kem_enc_derand_jazz(reg u64 ctp, reg u64 shkp, reg u64 pkp, reg ptr u8[KYBER_SYMBYTES] coins)
{
  stack u8[KYBER_SYMBYTES * 2] buf kr;
  stack u64 s_pkp s_ctp s_shkp;
  reg u64 t64;

  s_pkp = pkp;
  s_ctp = ctp;
  s_shkp = shkp;

  buf[0:32] = _sha3_256_32(buf[0:32], coins);

  pkp = s_pkp;

  t64 = KYBER_PUBLICKEYBYTES;
  buf[KYBER_SYMBYTES:32] = _sha3_256(buf[KYBER_SYMBYTES:32], pkp, t64);

  kr = _sha3_512_64(kr, buf);

  pkp = s_pkp;

  __indcpa_enc_0(s_ctp, buf[0:KYBER_INDCPA_MSGBYTES], pkp, kr[KYBER_SYMBYTES:KYBER_SYMBYTES]);

  ctp = s_ctp;
  t64 = KYBER_INDCPA_BYTES;
  kr[KYBER_SYMBYTES:32] = _sha3_256(kr[KYBER_SYMBYTES:32], ctp, t64);

  shkp = s_shkp;
  t64 = KYBER_SSBYTES;
  _shake256_64(shkp, t64, kr);
}

inline
fn __crypto_kem_dec_jazz(reg u64 shkp, reg u64 ctp, reg u64 skp)
{
  stack u8[KYBER_INDCPA_BYTES] ctpc;
  stack u8[2*KYBER_SYMBYTES] kr buf;
  stack u64 s_skp s_ctp s_shkp;
  reg u64 pkp hp zp t64 cnd;
  inline int i;

  s_shkp = shkp;
  s_ctp = ctp;

  buf[0:KYBER_INDCPA_MSGBYTES] = __indcpa_dec(buf[0:KYBER_INDCPA_MSGBYTES], ctp, skp);

  hp = #LEA(skp + 32); //hp = skp + 32;
  hp += 24 * KYBER_K * KYBER_N>>3;

  for i=0 to KYBER_SYMBYTES/8
  {
    t64 = (u64)[hp + 8*i];
    buf.[u64 KYBER_SYMBYTES + 8*i] = t64;
  }

  s_skp = skp;

  kr = _sha3_512_64(kr, buf);

  pkp = s_skp;
  pkp += 12 * KYBER_K * KYBER_N>>3;

  ctpc = __indcpa_enc_1(ctpc, buf[0:KYBER_INDCPA_MSGBYTES], pkp, kr[KYBER_SYMBYTES:KYBER_SYMBYTES]);

  ctp = s_ctp;
  cnd = __verify(ctp, ctpc);

  zp = s_skp;
  zp += 64;
  zp += 24 * KYBER_K * KYBER_N>>3;
  kr[0:KYBER_SYMBYTES] = __cmov(kr[0:KYBER_SYMBYTES], zp, cnd);

  t64 = KYBER_INDCPA_BYTES;
  kr[KYBER_SYMBYTES:32] = _sha3_256(kr[KYBER_SYMBYTES:32], ctp, t64);

  shkp = s_shkp;
  t64 = KYBER_SSBYTES;
  _shake256_64(shkp, t64, kr);
}
